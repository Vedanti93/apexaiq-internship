{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f01568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.28.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928988ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75ed83c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 saved successfully.\n",
      "Table 2 saved successfully.\n",
      "Table 3 saved successfully.\n",
      "Table 4 saved successfully.\n",
      "Table 5 saved successfully.\n",
      "Table 6 saved successfully.\n",
      "Table 7 saved successfully.\n",
      "Table 8 saved successfully.\n",
      "Table 9 saved successfully.\n",
      "Table 10 saved successfully.\n",
      "Table 11 saved successfully.\n",
      "Table 12 saved successfully.\n",
      "Table 13 saved successfully.\n",
      "Table 14 saved successfully.\n",
      "Table 15 saved successfully.\n",
      "Table 16 saved successfully.\n",
      "Table 17 saved successfully.\n",
      "Scraping completed. CSV files saved.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Java Version History Scraper\"\"\"\n",
    "\n",
    "#import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run browser in headless mode\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the Wikipedia page\n",
    "driver.get(\"https://en.wikipedia.org/wiki/Java_version_history\")\n",
    "time.sleep(2)  # Allow time for the page to load\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = driver.find_elements(By.XPATH, \"//table[co ntains(@class, 'wikitable')]\")\n",
    "\n",
    "# Loop through each table and extract data\n",
    "dataframes = []\n",
    "for index, table in enumerate(tables):\n",
    "    all_table_rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "    list_of_rows = []\n",
    "    \n",
    "    for each_row in all_table_rows:\n",
    "        list_of_data = [cell.text for cell in each_row.find_elements(By.XPATH, \".//th | .//td\")]\n",
    "        list_of_rows.append(list_of_data)\n",
    "    \n",
    "    if len(list_of_rows) > 1:  # Ensure table is not empty\n",
    "        df = pd.DataFrame(list_of_rows[1:], columns=list_of_rows[0])\n",
    "        dataframes.append(df)\n",
    "        df.to_csv(f\"java_version_table_{index+1}.csv\", index=False)\n",
    "        print(f\"Table {index+1} saved successfully.\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. CSV files saved.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffab0a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 saved successfully.\n",
      "Table 2 saved successfully.\n",
      "Table 3 saved successfully.\n",
      "Table 4 saved successfully.\n",
      "Table 5 saved successfully.\n",
      "Table 6 saved successfully.\n",
      "Table 7 saved successfully.\n",
      "Table 8 saved successfully.\n",
      "Table 9 saved successfully.\n",
      "Table 10 saved successfully.\n",
      "Table 11 saved successfully.\n",
      "Table 12 saved successfully.\n",
      "Table 13 saved successfully.\n",
      "Table 14 saved successfully.\n",
      "Table 15 saved successfully.\n",
      "Table 16 saved successfully.\n",
      "Table 17 saved successfully.\n",
      "Table 18 saved successfully.\n",
      "Table 19 saved successfully.\n",
      "Table 20 saved successfully.\n",
      "Table 21 saved successfully.\n",
      "Table 22 saved successfully.\n",
      "Table 23 saved successfully.\n",
      "Table 24 saved successfully.\n",
      "Table 25 saved successfully.\n",
      "Table 26 saved successfully.\n",
      "Table 27 saved successfully.\n",
      "Table 28 saved successfully.\n",
      "Table 29 saved successfully.\n",
      "Table 30 saved successfully.\n",
      "Table 31 saved successfully.\n",
      "Table 32 saved successfully.\n",
      "Table 33 saved successfully.\n",
      "Table 34 saved successfully.\n",
      "Table 35 saved successfully.\n",
      "Table 36 saved successfully.\n",
      "Table 37 saved successfully.\n",
      "Table 38 saved successfully.\n",
      "Table 39 saved successfully.\n",
      "Table 40 saved successfully.\n",
      "Table 41 saved successfully.\n",
      "Table 42 saved successfully.\n",
      "Table 43 saved successfully.\n",
      "Table 44 saved successfully.\n",
      "Table 45 saved successfully.\n",
      "Table 46 saved successfully.\n",
      "Table 47 saved successfully.\n",
      "Table 48 saved successfully.\n",
      "Table 49 saved successfully.\n",
      "Table 50 saved successfully.\n",
      "Table 51 saved successfully.\n",
      "Table 52 saved successfully.\n",
      "Table 53 saved successfully.\n",
      "Table 54 saved successfully.\n",
      "Table 55 saved successfully.\n",
      "Table 56 saved successfully.\n",
      "Table 57 saved successfully.\n",
      "Table 58 saved successfully.\n",
      "Table 59 saved successfully.\n",
      "Table 60 saved successfully.\n",
      "Table 61 saved successfully.\n",
      "Table 62 saved successfully.\n",
      "Table 63 saved successfully.\n",
      "Table 64 saved successfully.\n",
      "Table 65 saved successfully.\n",
      "Table 66 saved successfully.\n",
      "Table 67 saved successfully.\n",
      "Table 68 saved successfully.\n",
      "Table 69 saved successfully.\n",
      "Table 70 saved successfully.\n",
      "Table 71 saved successfully.\n",
      "Table 72 saved successfully.\n",
      "Table 73 saved successfully.\n",
      "Table 74 saved successfully.\n",
      "Table 75 saved successfully.\n",
      "Table 76 saved successfully.\n",
      "Table 77 saved successfully.\n",
      "Table 78 saved successfully.\n",
      "Table 79 saved successfully.\n",
      "Table 80 saved successfully.\n",
      "Table 81 saved successfully.\n",
      "Table 82 saved successfully.\n",
      "Table 83 saved successfully.\n",
      "Table 84 saved successfully.\n",
      "Table 85 saved successfully.\n",
      "Table 86 saved successfully.\n",
      "Table 87 saved successfully.\n",
      "Table 88 saved successfully.\n",
      "Table 89 saved successfully.\n",
      "Table 90 saved successfully.\n",
      "Table 91 saved successfully.\n",
      "Table 92 saved successfully.\n",
      "Table 93 saved successfully.\n",
      "Table 94 saved successfully.\n",
      "Table 95 saved successfully.\n",
      "Table 96 saved successfully.\n",
      "Table 97 saved successfully.\n",
      "Table 98 saved successfully.\n",
      "Table 99 saved successfully.\n",
      "Table 100 saved successfully.\n",
      "Table 101 saved successfully.\n",
      "Table 102 saved successfully.\n",
      "Table 103 saved successfully.\n",
      "Table 104 saved successfully.\n",
      "Table 105 saved successfully.\n",
      "completed. CSV files saved.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"sdk Version History Scraper\"\"\"\n",
    "\n",
    "#import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run browser in headless mode\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "\n",
    "driver.get(\"https://dotnet.microsoft.com/en-us/download/dotnet/8.0\")\n",
    "time.sleep(2)  \n",
    "# Find all tables on the page\n",
    "tables = driver.find_elements(By.XPATH, \"//table[contains(@class, 'table table-bordered table-sm')]\")\n",
    "\n",
    "# Loop through each table and extract data\n",
    "dataframes = []\n",
    "for index, table in enumerate(tables):\n",
    "    all_table_rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "    list_of_rows = []\n",
    "    \n",
    "    for each_row in all_table_rows:\n",
    "        list_of_data = [cell.text for cell in each_row.find_elements(By.XPATH, \".//th | .//td\")]\n",
    "        list_of_rows.append(list_of_data)\n",
    "    \n",
    "    if len(list_of_rows) > 1:  # Ensure table is not empty\n",
    "        df = pd.DataFrame(list_of_rows[1:], columns=list_of_rows[0])\n",
    "        dataframes.append(df)\n",
    "        df.to_csv(f\"sdk_version_table_{index+1}.csv\", index=False)\n",
    "        print(f\"Table {index+1} saved successfully.\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"completed. CSV files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa4d87b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed. Data saved to 'java_version_history_combined.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run browser in headless mode\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the Wikipedia page\n",
    "driver.get(\"https://en.wikipedia.org/wiki/Java_version_history\")\n",
    "time.sleep(2)  # Allow time for the page to load\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = driver.find_elements(By.XPATH, \"//table[contains(@class, 'wikitable')]\")\n",
    "\n",
    "# Prepare a list to hold all dataframes\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each table and extract data\n",
    "for table in tables:\n",
    "    all_table_rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "    list_of_rows = []\n",
    "    \n",
    "    for each_row in all_table_rows:\n",
    "        list_of_data = [cell.text for cell in each_row.find_elements(By.XPATH, \".//th | .//td\")]\n",
    "        list_of_rows.append(list_of_data)\n",
    "\n",
    "    if len(list_of_rows) > 1:  # Ensure table is not empty\n",
    "        df = pd.DataFrame(list_of_rows[1:], columns=list_of_rows[0])\n",
    "        \n",
    "        # Replace null values with \"-\"\n",
    "        df.fillna(\"-\", inplace=True)\n",
    "        \n",
    "        # Ensure column names are unique by appending numbers if necessary\n",
    "        df.columns = [f\"{col}_{i}\" if df.columns.tolist().count(col) > 1 else col for i, col in enumerate(df.columns)]\n",
    "        \n",
    "        # Split rows with multiple values in one cell into separate rows\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":  # Check if column contains string values that can be split\n",
    "                df[col] = df[col].apply(lambda x: x.split(\",\") if isinstance(x, str) else [x])\n",
    "                df = df.explode(col).reset_index(drop=True)\n",
    "\n",
    "        # Append the current table's data to the combined dataframe\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a single CSV\n",
    "combined_df.to_csv(\"java_version_history_combined.csv\", index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'java_version_history_combined.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18881e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed. Data saved to 'java_version_history_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run browser in headless mode\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the Wikipedia page\n",
    "driver.get(\"https://en.wikipedia.org/wiki/Java_version_history\")\n",
    "time.sleep(2)  # Allow time for the page to load\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = driver.find_elements(By.XPATH, \"//table[contains(@class, 'wikitable')]\")\n",
    "\n",
    "# Prepare a list to hold all dataframes\n",
    "all_data = []\n",
    "\n",
    "# Loop through each table and extract data\n",
    "for table in tables:\n",
    "    all_table_rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "    list_of_rows = []\n",
    "    \n",
    "    for each_row in all_table_rows:\n",
    "        list_of_data = [cell.text.strip() for cell in each_row.find_elements(By.XPATH, \".//th | .//td\")]\n",
    "        list_of_rows.append(list_of_data)\n",
    "\n",
    "    if len(list_of_rows) > 1:  # Ensure table is not empty\n",
    "        df = pd.DataFrame(list_of_rows[1:], columns=list_of_rows[0])  # First row as header\n",
    "        \n",
    "        # Remove empty columns that appear due to inconsistent tables\n",
    "        df = df.dropna(how=\"all\", axis=1)  # Drop completely empty columns\n",
    "        df = df.dropna(how=\"all\", axis=0)  # Drop completely empty rows\n",
    "        \n",
    "        # Ensure column names are unique\n",
    "        df.columns = [f\"{col}_{i}\" if df.columns.tolist().count(col) > 1 else col for i, col in enumerate(df.columns)]\n",
    "        \n",
    "        # Replace null values with \"-\"\n",
    "        df.fillna(\"-\", inplace=True)\n",
    "        \n",
    "        # Exploding multiple values stored in one cell (handling multi-line cases)\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                df[col] = df[col].apply(lambda x: x.split(\"\\n\") if isinstance(x, str) else [x])\n",
    "                df = df.explode(col).reset_index(drop=True)\n",
    "\n",
    "        # Filter out unwanted legend rows\n",
    "        df = df[~df.iloc[:, 0].str.contains(\"Legend|Old version|still maintained|Latest version|Future release\", na=False, case=False)]\n",
    "\n",
    "        all_data.append(df)\n",
    "\n",
    "# Combine all dataframes into a single CSV\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "final_df.to_csv(\"java_version_history_cleaned.csv\", index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'java_version_history_cleaned.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcbe7c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 saved successfully.\n",
      "Table 2 saved successfully.\n",
      "Table 3 saved successfully.\n",
      "Table 4 saved successfully.\n",
      "Table 5 saved successfully.\n",
      "Table 6 saved successfully.\n",
      "Table 7 saved successfully.\n",
      "Table 8 saved successfully.\n",
      "Table 9 saved successfully.\n",
      "Table 10 saved successfully.\n",
      "Table 11 saved successfully.\n",
      "Table 12 saved successfully.\n",
      "Table 13 saved successfully.\n",
      "Table 14 saved successfully.\n",
      "Table 15 saved successfully.\n",
      "Table 16 saved successfully.\n",
      "Table 17 saved successfully.\n",
      "Scraping completed. All tables saved separately and combined.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run browser in headless mode\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/Java_version_history\"\n",
    "driver.get(url)\n",
    "time.sleep(2)  # Allow time for the page to load\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = driver.find_elements(By.XPATH, \"//table[contains(@class, 'wikitable')]\")\n",
    "\n",
    "# Prepare a list to hold all dataframes\n",
    "all_data = []\n",
    "\n",
    "# Loop through each table and extract data\n",
    "for index, table in enumerate(tables):\n",
    "    all_table_rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "    list_of_rows = []\n",
    "    \n",
    "    for each_row in all_table_rows:\n",
    "        list_of_data = [cell.text.strip() for cell in each_row.find_elements(By.XPATH, \".//th | .//td\")]\n",
    "        list_of_rows.append(list_of_data)\n",
    "\n",
    "    if len(list_of_rows) > 1:  # Ensure table is not empty\n",
    "        df = pd.DataFrame(list_of_rows[1:], columns=list_of_rows[0])  # First row as header\n",
    "\n",
    "        # Remove empty columns\n",
    "        df.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "        # Ensure column names are unique (avoids duplicate column errors)\n",
    "        df.columns = [f\"{col}_{i}\" if df.columns.tolist().count(col) > 1 else col for i, col in enumerate(df.columns)]\n",
    "\n",
    "        # Remove completely empty rows\n",
    "        df.dropna(axis=0, how=\"all\", inplace=True)\n",
    "\n",
    "        # Handle multi-line values (explode into multiple rows)\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                df[col] = df[col].apply(lambda x: x.split(\"\\n\") if isinstance(x, str) else [x])\n",
    "                df = df.explode(col).reset_index(drop=True)\n",
    "\n",
    "        # Save each table separately\n",
    "        df.to_csv(f\"java_version_table_{index+1}.csv\", index=False)\n",
    "        print(f\"Table {index+1} saved successfully.\")\n",
    "\n",
    "        # Append to combined data list\n",
    "        all_data.append(df)\n",
    "\n",
    "# Save all tables as one combined CSV\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "final_df.to_csv(\"java_version_history_combined.csv\", index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. All tables saved separately and combined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bdf9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
